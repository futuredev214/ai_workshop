import json
import queue
import sounddevice as sd
from vosk import Model, KaldiRecognizer
from utils import log

class SpeechToTextEngine:
    def __init__(self, model_path: str):
        """
        ìŒì„± ì¸ì‹ ì—”ì§„ ì´ˆê¸°í™”

        Args:
            model_path (str): Vosk ëª¨ë¸ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ
        """
        # Vosk ëª¨ë¸ ë¡œë“œ
        self.model = Model(model_path)

        # 16kHz ìƒ˜í”Œë ˆì´íŠ¸ë¡œ ì¸ì‹ê¸° ìƒì„±
        # 16000 = ìŒì„± ì¸ì‹ì— ì í•©í•œ í‘œì¤€ ì£¼íŒŒìˆ˜
        self.recognizer = KaldiRecognizer(self.model, 16000)

        # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì„ì‹œ ì €ì¥í•  í (queue = ëŒ€ê¸°ì—´)
        self.audio_queue = queue.Queue()

    def _audio_callback(self, indata, frames, time, status):
        """
        ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ê°€ ë“¤ì–´ì˜¬ ë•Œë§ˆë‹¤ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜

        Args:
            indata: ë§ˆì´í¬ë¡œ ë“¤ì–´ì˜¨ ì˜¤ë””ì˜¤ ë°ì´í„° (numpy array)
            frames: ì˜¤ë””ì˜¤ í”„ë ˆì„ ê°œìˆ˜
            time: íƒ€ì„ìŠ¤íƒ¬í”„
            status: ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ìƒíƒœ
        """
        if status:
            log(f"[ì˜¤ë””ì˜¤ ì—ëŸ¬] {status}")

        # ë“¤ì–´ì˜¨ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ íì— ì €ì¥
        self.audio_queue.put(bytes(indata))

    def listen_and_transcribe(self):
        """
        ë§ˆì´í¬ë¡œ ìŒì„±ì„ ë“£ê³  í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Returns:
            str: ì¸ì‹ëœ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´)
        """
        log("\nğŸ¤ ë“£ê³  ìˆìŠµë‹ˆë‹¤... ë§ì”€í•˜ì„¸ìš”!")

        try:
            # ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
            # samplerate=16000: ì´ˆë‹¹ 16000ë²ˆ ìƒ˜í”Œë§ (ìŒì„± ì¸ì‹ í‘œì¤€)
            # blocksize=8000: í•œ ë²ˆì— ì²˜ë¦¬í•  ìƒ˜í”Œ ê°œìˆ˜
            # channels=1: ëª¨ë…¸ (ìŠ¤í…Œë ˆì˜¤ëŠ” 2)
            with sd.RawInputStream(
                    samplerate=16000,
                    blocksize=8000,
                    dtype='int16',
                    channels=1,
                    callback=self._audio_callback
            ):
                while True:
                    # íì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    data = self.audio_queue.get()

                    # Vosk ì¸ì‹ê¸°ì— ë°ì´í„° ì „ë‹¬
                    if self.recognizer.AcceptWaveform(data):
                        # ë¬¸ì¥ì´ ì™„ì„±ë˜ì—ˆì„ ë•Œ
                        result = json.loads(self.recognizer.Result())
                        text = result.get('text', '')

                        if text:
                            log(f"âœ… ì¸ì‹ë¨: {text}")
                            return text
                    else:
                        # ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ (partial result)
                        partial = json.loads(self.recognizer.PartialResult())
                        partial_text = partial.get('partial', '')

                        if partial_text:
                            log(f"ğŸ”„ ì¸ì‹ ì¤‘: {partial_text}", end='\r')

        except KeyboardInterrupt:
            log("\nâš ï¸ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            return ""
        except Exception as e:
            log(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
            return ""