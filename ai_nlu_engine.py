import os
from utils import log
import pandas as pd
from keybert import KeyBERT

# ì˜¤í”„ë¼ì¸ í—ˆìš© (ëª¨ë¸ì´ ë¡œì»¬ì— ìˆì„ ë•Œ)
os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'
os.environ["TRANSFORMERS_OFFLINE"] = os.getenv("TRANSFORMERS_OFFLINE", "0")

from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import re
import torch

class UniversalNluEngine:
    """ë²”ìš© ì œì–´ ì‹œìŠ¤í…œ NLU ì—”ì§„"""
    def __init__(self):
        # ì§€ì›í•˜ëŠ” ëª…ë ¹ íƒ€ì…
        self.COMMAND_TYPES = [
            "control", "broadcast", "log", "read", "write"
        ]

        # ë ˆì´ë¸” â†’ ê°€ì„¤ë¬¸ ë§¤í•‘
        self.HYP_DETAILED = {
            "ALERT": {
                "description": "ì‚¬ìš©ì ë˜ëŠ” ê´€ë¦¬ìì—ê²Œ ê²½ê³ , ì•Œë¦¼, ë¹„ìƒ ìƒí™©ì„ ì•Œë¦¬ëŠ” ë°©ì†¡ì´ë‚˜ ë©”ì‹œì§€ ì „ì†¡ì„ ì§€ì‹œí•©ë‹ˆë‹¤.",
                "examples": [
                    "ì¹¨ìˆ˜ ìœ„í—˜ ê²½ë³´ë¥¼ ë°œë ¹í•˜ë¼.",
                    "ê´€ë¦¬ìì—ê²Œ ì¦‰ì‹œ ë¬¸ì ì•Œë¦¼ì„ ë³´ë‚´.",
                    "ë¹„ìƒ ë°©ì†¡ ì‹œìŠ¤í…œì„ ì‘ë™ì‹œì¼œë¼.",
                    "ì‚¬ì´ë Œì„ ìš¸ë ¤."
                ],
                "action_verbs": ["ì•Œë¦¬ë‹¤", "ê²½ë³´í•˜ë‹¤", "ë°©ì†¡í•˜ë‹¤", "ë°œë ¹í•˜ë‹¤", "ì „ì†¡í•˜ë‹¤", "ë³´ë‚´ë‹¤", "ìš¸ë¦¬ë‹¤"],
                "target_objects": ["ê²½ë³´", "ì•Œë¦¼", "ë¹„ìƒ ë°©ì†¡", "ì‚¬ì´ë Œ", "ì•ˆë‚´ ë°©ì†¡", "ê´€ë¦¬ì", "ì‚¬ìš©ì"]
            },

            "LOG": {
                "description": "í˜„ì¬ ìƒíƒœ, íŠ¹ì • ì´ë²¤íŠ¸ ë°œìƒ, ì„¼ì„œ ë°ì´í„° ê°’ ë“±ì„ ì‹œìŠ¤í…œ ë¡œê·¸ íŒŒì¼ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì— ê¸°ë¡(ì €ì¥)í•˜ë¼ëŠ” ì§€ì‹œì…ë‹ˆë‹¤.",
                "examples": [
                    "í˜„ì¬ ìˆ˜ìœ„ë¥¼ ë¡œê·¸ì— ê¸°ë¡í•´.",
                    "ëª¨ë“  ì„¼ì„œ ê°’ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•´.",
                    "íŒí”„ ì‘ë™ ì´ë²¤íŠ¸ ë¡œê·¸ë¥¼ ë‚¨ê²¨ë¼."
                ],
                "action_verbs": ["ê¸°ë¡í•˜ë‹¤", "ì €ì¥í•˜ë‹¤", "ë¡œê·¸ë¥¼ ë‚¨ê¸°ë‹¤", "ì“°ë‹¤"],
                "target_objects": ["ë¡œê·¸", "ë°ì´í„°", "ì´ë²¤íŠ¸", "í˜„ì¬ ìƒíƒœ", "ê°’", "íŒŒì¼", "DB"]
            },

            "DO": {
                "description": "ë””ì§€í„¸ ì¶œë ¥(DO) í¬íŠ¸ë¥¼ ì œì–´í•˜ì—¬ íŠ¹ì • ì¥ì¹˜(ì˜ˆ: ë¦´ë ˆì´, íŒí”„, ë°¸ë¸Œ)ë¥¼ ì¼œê±°ë‚˜(ON) ë„ëŠ”(OFF) ë™ì‘ì„ ì§€ì‹œí•©ë‹ˆë‹¤.",
                "examples": [
                    "1ë²ˆ íŒí”„ë¥¼ ì¼œë¼.",
                    "ë°¸ë¸Œ 3ë²ˆì„ ë‹«ì•„.",
                    "DO 2ë²ˆ í¬íŠ¸ OFF ì‹œì¼œ.",
                    "ê²½ê´‘ë“±ì„ ì‘ë™ì‹œì¼œë¼."
                ],
                "action_verbs": ["ì¼œë‹¤", "ë„ë‹¤", "ì‘ë™ì‹œí‚¤ë‹¤", "ì •ì§€ì‹œí‚¤ë‹¤", "ì—´ë‹¤", "ë‹«ë‹¤", "ON", "OFF"],
                "target_objects": ["íŒí”„", "ë°¸ë¸Œ", "ë¦´ë ˆì´", "ëª¨í„°", "íŒ¬", "ê²½ê´‘ë“±", "DO í¬íŠ¸"]
            },
            "DI": {
                "description": "ë””ì§€í„¸ ì…ë ¥(DI) í¬íŠ¸ì˜ í˜„ì¬ ìƒíƒœ(ON/OFF, High/Low)ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì½ì–´ì˜¤ë¼ëŠ” ì§€ì‹œì…ë‹ˆë‹¤.",
                "examples": [
                    "1ë²ˆ ìŠ¤ìœ„ì¹˜ ìƒíƒœ í™•ì¸í•´.",
                    "DI 3ë²ˆ ì…ë ¥ ê°’ì´ ë­ì•¼?",
                    "ë¬¸ ì—´ë¦¼ ì„¼ì„œê°€ ê°ì§€ëëŠ”ì§€ ì•Œë ¤ì¤˜.",
                    "ë¹„ìƒ ì •ì§€ ë²„íŠ¼ì´ ëˆŒë ¸ì–´?"
                ],
                "action_verbs": ["í™•ì¸í•˜ë‹¤", "ì½ë‹¤", "ìƒíƒœë¥¼ ë³´ë‹¤", "ê°ì§€í•˜ë‹¤", "ì…ë ¥ê°’"],
                "target_objects": ["ìŠ¤ìœ„ì¹˜", "ì„¼ì„œ", "ë²„íŠ¼", "ë¬¸ ì—´ë¦¼", "DI í¬íŠ¸", "ì…ë ¥ ìƒíƒœ"]
            },
            "AO": {
                "description": "ì•„ë‚ ë¡œê·¸ ì¶œë ¥(AO) í¬íŠ¸ë¥¼ í†µí•´ íŠ¹ì • ì „ì••ì´ë‚˜ ì „ë¥˜(ì˜ˆ: 0-10V, 4-20mA) ê°’ì„ ì„¤ì •í•˜ê±°ë‚˜ ì œì–´í•˜ë¼ëŠ” ì§€ì‹œì…ë‹ˆë‹¤.",
                "examples": [
                    "AO 1ë²ˆ í¬íŠ¸ì— 5Vë¥¼ ì¶œë ¥í•´.",
                    "ë°¸ë¸Œ ê°œë°©ë„ë¥¼ 50%ë¡œ ì„¤ì •í•´.",
                    "ì•„ë‚ ë¡œê·¸ ì¶œë ¥ìœ¼ë¡œ ëª¨í„° ì†ë„ë¥¼ 80%ë¡œ ì¡°ì ˆí•´."
                ],
                "action_verbs": ["ì¶œë ¥í•˜ë‹¤", "ì„¤ì •í•˜ë‹¤", "ì œì–´í•˜ë‹¤", "ì¡°ì ˆí•˜ë‹¤", "ë§ì¶”ë‹¤", "ë³´ë‚´ë‹¤"],
                "target_objects": ["ì „ì••", "ì „ë¥˜", "ë°¸ë¸Œ ê°œë°©ë„", "ëª¨í„° ì†ë„", "AO í¬íŠ¸", "ì¶œë ¥ê°’", "í¼ì„¼íŠ¸"]
            },
            "AI": {
                "description": "ì•„ë‚ ë¡œê·¸ ì…ë ¥(AI) í¬íŠ¸ì— ì—°ê²°ëœ ì„¼ì„œì˜ í˜„ì¬ ê°’(ì „ì••, ì „ë¥˜, ë˜ëŠ” ë³€í™˜ëœ ë¬¼ë¦¬ëŸ‰)ì„ ì½ì–´ì˜¤ë¼ëŠ” ì§€ì‹œì…ë‹ˆë‹¤.",
                "examples": [
                    "AI 2ë²ˆ í¬íŠ¸ ê°’ ì½ì–´ì™€.",
                    "í˜„ì¬ ì˜¨ë„ ì„¼ì„œ ê°’ ëª‡ ë„ì•¼?",
                    "ì••ë ¥ ì„¼ì„œê°€ ì¸¡ì •í•œ ê°’ì´ ë­ì•¼?",
                    "ì•„ë‚ ë¡œê·¸ ì…ë ¥ 1ë²ˆ ì±„ë„ ì „ì•• í™•ì¸í•´."
                ],
                "action_verbs": ["ì½ë‹¤", "í™•ì¸í•˜ë‹¤", "ì¸¡ì •í•˜ë‹¤", "ê°’ì„ ê°€ì ¸ì˜¤ë‹¤", "ì•Œë ¤ì£¼ë‹¤"],
                "target_objects": ["ì˜¨ë„ ì„¼ì„œ", "ì••ë ¥ ì„¼ì„œ", "ì „ì••ê°’", "ì „ë¥˜ê°’", "AI í¬íŠ¸", "ì„¼ì„œ ê°’", "ì¸¡ì •ê°’"]
            },

            "COM": {
                "description": "ì‹œë¦¬ì–¼ í¬íŠ¸(RS-232, 485)ë‚˜ íŠ¹ì • í†µì‹  ì±„ë„(TCP/IP)ì„ í†µí•´ ë°ì´í„°ë¥¼ ì „ì†¡í•˜ê±°ë‚˜ ìˆ˜ì‹ í•˜ë¼ëŠ” ì§€ì‹œì…ë‹ˆë‹¤.",
                "examples": [
                    "COM1 í¬íŠ¸ë¡œ 'START' ë¬¸ìì—´ì„ ë³´ë‚´.",
                    "RS485 í†µì‹ ì„ í†µí•´ ì™¸ë¶€ ì¥ì¹˜ ê°’ì„ ì½ì–´ì™€.",
                    "ì‹œë¦¬ì–¼ í†µì‹  ì—°ê²°ì„ í™•ì¸í•´."
                ],
                "action_verbs": ["ì „ì†¡í•˜ë‹¤", "ë³´ë‚´ë‹¤", "ìˆ˜ì‹ í•˜ë‹¤", "ì½ë‹¤", "ì“°ë‹¤", "ì—°ê²°í•˜ë‹¤", "í™•ì¸í•˜ë‹¤"],
                "target_objects": ["COM í¬íŠ¸", "ì‹œë¦¬ì–¼", "RS485", "RS232", "ë°ì´í„°", "ë¬¸ìì—´", "ì™¸ë¶€ ì¥ì¹˜"]
            },

            # "WATERLEVEL": {
            #     "description": "ìˆ˜ìœ„ ì„¼ì„œì˜ í˜„ì¬ ê°’(ìˆ˜ìœ„ ë†’ì´)ì„ ë¬»ê±°ë‚˜, íŠ¹ì • ìˆ˜ìœ„ ê°’ê³¼ ê´€ë ¨ëœ ë™ì‘(ì˜ˆ: íŒí”„ ì œì–´)ì„ ì§€ì‹œí•©ë‹ˆë‹¤.",
            #     "examples": [
            #         "í˜„ì¬ ì €ìˆ˜ì§€ ìˆ˜ìœ„ ëª‡ ë¯¸í„°ì•¼?",
            #         "ìˆ˜ìœ„ê°€ 3më¥¼ ë„˜ìœ¼ë©´ 1ë²ˆ íŒí”„ë¥¼ ì¼œ.",
            #         "ìˆ˜ìœ„ ì„¼ì„œ ê°’ ì‹¤ì‹œê°„ìœ¼ë¡œ ì•Œë ¤ì¤˜."
            #     ],
            #     "action_verbs": ["ì½ë‹¤", "í™•ì¸í•˜ë‹¤", "ì¸¡ì •í•˜ë‹¤", "ì•Œë ¤ì£¼ë‹¤", "...ì´ë©´ ...í•´ë¼"],
            #     "target_objects": ["ìˆ˜ìœ„", "ìˆ˜ìœ„ê°’", "ìˆ˜ìœ„ ì„¼ì„œ", "ìˆ˜ìœ„ê³„", "ì €ìˆ˜ì§€", "ìˆ˜ì¡°"]
            # },
            # "RAINFALL": {
            #     "description": "ìš°ëŸ‰ê³„(ê°•ìˆ˜ëŸ‰ ì„¼ì„œ)ê°€ ì¸¡ì •í•œ ê°’(ëˆ„ì  ê°•ìš°, ì‹œê°„ë‹¹ ê°•ìš° ë“±)ì„ ë¬»ëŠ” ì§€ì‹œì…ë‹ˆë‹¤.",
            #     "examples": [
            #         "ì˜¤ëŠ˜ ëˆ„ì  ê°•ìˆ˜ëŸ‰ì´ ì–¼ë§ˆì•¼?",
            #         "ì‹œê°„ë‹¹ ê°•ìš°ëŸ‰ ì•Œë ¤ì¤˜.",
            #         "ìš°ëŸ‰ ì„¼ì„œ ê°’ ì¢€ ì½ì–´ì™€."
            #     ],
            #     "action_verbs": ["ì½ë‹¤", "í™•ì¸í•˜ë‹¤", "ì¸¡ì •í•˜ë‹¤", "ì•Œë ¤ì£¼ë‹¤"],
            #     "target_objects": ["ê°•ìˆ˜ëŸ‰", "ê°•ìš°ëŸ‰", "ëˆ„ì  ê°•ìˆ˜ëŸ‰", "ì‹œê°„ë‹¹ ê°•ìš°ëŸ‰", "ìš°ëŸ‰ê³„", "ê°•ìˆ˜ ì„¼ì„œ"]
            # },
            # "BATTERY_VOLTAGE": {
            #     "description": "ì‹œìŠ¤í…œì˜ ì£¼ ì „ì› ë˜ëŠ” ë°°í„°ë¦¬ì˜ í˜„ì¬ ì „ì•• ê°’ì´ë‚˜ ì „ì› ìƒíƒœ(ì”ëŸ‰)ë¥¼ ë¬»ëŠ” ì§€ì‹œì…ë‹ˆë‹¤.",
            #     "examples": [
            #         "ë°°í„°ë¦¬ ì „ì•• ëª‡ ë³¼íŠ¸ ë‚¨ì•˜ì–´?",
            #         "í˜„ì¬ ì „ì› ìƒíƒœ ì–´ë•Œ?",
            #         "ë°°í„°ë¦¬ ì”ëŸ‰ í™•ì¸í•´ ì¤˜.",
            #         "UPS ì „ì•• ì²´í¬í•´ ë´."
            #     ],
            #     "action_verbs": ["í™•ì¸í•˜ë‹¤", "ì½ë‹¤", "ì•Œë ¤ì£¼ë‹¤", "ì²´í¬í•˜ë‹¤", "ì¸¡ì •í•˜ë‹¤"],
            #     "target_objects": ["ë°°í„°ë¦¬", "ì „ì••", "ë°°í„°ë¦¬ ì „ì••", "ì „ì› ìƒíƒœ", "ì”ëŸ‰", "UPS"]
            # }
        }

        # êµ¬ë¶„ íƒ€ì…
        self.what_TYPES = {
            # ê¸´ê¸‰ ì‹œ, ê²½ë³´ í›„ ë¡œê·¸ ë‚¨ê¸°ê¸°
            "ALERT": [
                "ê²½ë³´", "ê²½ê³ ", "ì•ŒëŒ", "ë¹„ìƒ", "ê¸´ê¸‰", "alert", "alarm",
                "ì‚¬ì´ë Œ", "ê²½ê³ ìŒ", "ë¹„ìƒì‹ í˜¸", "ê²½ë³´ë°©ì†¡", "ê²½ë³´ë“±", "ê²½ë³´ë°œìƒ", "alert signal"
            ],
            "LOG": [
                "ë¡œê·¸", "ê¸°ë¡", "ì €ì¥", "log", "history", "ë°ì´í„°ê¸°ë¡", "ì´ë ¥ë‚¨ê¸°ê¸°", "log save", "log record"
            ],

            # ê¸°ë³¸ I/O
            "DO": ["do", "ë””ì˜¤", "ë””ì§€í„¸ ì¶œë ¥", "digital output"],
            "DI": ["di", "ë””ì•„ì´", "ë””ì§€í„¸ ì…ë ¥", "digital input"],
            "AO": ["ao", "ì—ì´ì˜¤", "ì•„ë‚ ë¡œê·¸ ì¶œë ¥", "analog output"],
            "AI": ["ai", "ì—ì´ì•„ì´", "ì•„ë‚ ë¡œê·¸ ì…ë ¥", "analog input"],

            # í†µì‹  ìƒíƒœ
            # "COM": ["uart", "com", "ì‹œë¦¬ì–¼", "serial", "í†µì‹ í¬íŠ¸", "í¬íŠ¸ìƒíƒœ", "í†µì‹ ì—°ê²°", "tx", "rx"],

            # ì„¼ì„œ
            # "WATERLEVEL": [
            #     "ìˆ˜ìœ„", "waterlevel", "ìˆ˜ìœ„ì„¼ì„œ", "level", "water level",
            #     "ìˆ˜ìœ„ê°’", "ìˆ˜ìœ„ì¸¡ì •", "ì €ìˆ˜ìœ„", "ê³ ìˆ˜ìœ„", "water sensor"
            # ],
            # "RAINFALL": [
            #     "ìš°ëŸ‰", "rainfall", "rain", "ë¹„", "ê°•ìˆ˜", "ê°•ìš°", "rain sensor",
            #     "ìš°ëŸ‰ì„¼ì„œ", "ê°•ìˆ˜ëŸ‰", "rain gauge", "rain data"
            # ],
            # "BATTERY_VOLTAGE": [
            #     "ë°°í„°ë¦¬ ì „ì••", "batteryvoltage", "ë°°í„°ë¦¬", "ì „ì••", "ì „ì›ì „ì••",
            #     "ë°°í„°ë¦¬ ìƒíƒœ", "battery voltage", "battery level", "ì „ì›ìƒíƒœ",
            #     "battery sensor", "ì „ì••ê°’"
            # ]
        }

        self.ACTION_ON = ["ì¼œ", "ì¼œì¤˜", "on", "start", "í™œì„±", "í™œì„±í™”", "ì‘ë™"]
        self.ACTION_OFF = ["êº¼", "êº¼ì¤˜", "ë„", "off", "stop", "ë¹„í™œì„±", "ë¹„í™œì„±í™”", "ì •ì§€"]
        self.ACTION_READ = ["ì½", "read", "ì¡°íšŒ", "í™•ì¸", "ê°€ì ¸ì™€"]
        self.ACTION_WRITE = ["ì“°", "write", "ì„¤ì •", "ì„¸íŒ…", "ë³€ê²½", "ë°”ê¿”"]
        self.ACTION_QUERY = ["ìƒíƒœ", "status", "ì–´ë•Œ", "ì–´ë–»ê²Œ", "query"]

        # ì¡ìŒ í‚¤ì›Œë“œ
        self.NOISE = ["ì•¼", "ìŒ", "ì–´", "ìœ¼", "ì•„", "ì´ì œ", "ì¢€", "ì•½ê°„", "ê·¸", "ì €", "ë­", "ë­ì‹œê¸°",
                      "ê·¸ê±°", "ì €ê±°", "ì´ê±°", "ìˆì–ì•„", "ìˆì–ì•„ìš”", "ìš”", "ì ê¹", "ë¹¨ë¦¬"]


        log("ğŸ¤– AI ëª¨ë¸ ë¡œë”© ì¤‘...")
        model_dir = r"D:\models\xlmR_xnli"

        # ì˜µì…˜ 2: í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ (KoBERT ê¸°ë°˜)
        self.classifier = pipeline(
            "zero-shot-classification",
            model=AutoModelForSequenceClassification.from_pretrained(model_dir, local_files_only=True),
            tokenizer=AutoTokenizer.from_pretrained(model_dir, local_files_only=True, use_fast=True),
        )

        self.keyword_extractor = KeyBERT('distiluse-base-multilingual-cased-v2')

        # HYP_DETAILED ê²€ì¦
        for label in self.what_TYPES.keys():
            if label not in self.HYP_DETAILED:
                log(f"âš ï¸ ê²½ê³ : {label}ì— ëŒ€í•œ HYP_DETAILED ì—†ìŒ")

        log("âœ… HYP_DETAILED ê²€ì¦ ì™„ë£Œ")

        log("âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

    # 0. ì¡ìŒ ì²˜ë¦¬
    def _preprocess(self, text: str) -> str:
        """ì¡ìŒ ì œê±° ì „ì²˜ë¦¬"""
        t = text.strip().lower()
        for n in self.NOISE:
            t = re.sub(r'\b' + re.escape(n) + r'\b', ' ', t)
            t = t.replace(' ' + n + ' ', ' ').replace(' ' + n, ' ').replace(n + ' ', ' ')
        return re.sub(r'\s+', ' ', t).strip()

    def _extract_keywords(self, text: str, top_n: int = 5):
        """ë¬¸ì¥ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ (ëª…ì‚¬, í–‰ìœ„ì–´ ë“±)"""
        text = self._preprocess(text)
        log(f"   ì¡ìŒ ì œê±° í›„ : {text}")
        keywords = self.keyword_extractor.extract_keywords(
            text,
            keyphrase_ngram_range=(1, 1), # ì—°ì†ëœ ë‹¨ì–´ n ë¶€í„° mê°œ ê¹Œì§€ í•˜ë‚˜ì˜ í‚¤ì›Œë“œ í›„ë³´ë¡œ ë³¸ë‹¤.
            stop_words=self.NOISE,        # ë¶ˆí•„ìš”í•œ ë¶ˆìš©ì–´ ì œê±°
            top_n=top_n                   # ëª‡ ê°œì˜ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  ì§€ ê²°ì •
        )
        print(f"í‚¤ì›Œë“œ ì¤‘ìš”ë„ ë¶„ì„ : {[(kw, score) for kw, score in keywords]}")
        # [('ê²½ë³´êµ­', 0.74), ('í¬íŠ¸', 0.68)...] â†’ ['ê²½ë³´êµ­', 'í¬íŠ¸', ...]
        return [kw for kw, score in keywords]

    def _build_hypothesis(self, label: str) -> str:
        """
        ë ˆì´ë¸”ì— ë§ëŠ” ìƒì„¸í•œ ê°€ì„¤ ë¬¸ì¥ ìƒì„±

        Args:
            label: "DO", "ALERT" ê°™ì€ ì¥ì¹˜ ì½”ë“œ

        Returns:
            str: "ì´ ë¬¸ì¥ì€ ë””ì§€í„¸ ì¶œë ¥(DO) í¬íŠ¸ë¥¼ ì œì–´í•˜ì—¬..."
        """
        if label not in self.HYP_DETAILED:
            return f"ì´ ë¬¸ì¥ì€ {label}ì— ê´€í•œ ì§€ì‹œë‹¤."

        detail = self.HYP_DETAILED[label]

        # description í™œìš©
        desc = detail["description"]

        # examples ì¼ë¶€ ì¶”ê°€ (ì„ íƒ ì‚¬í•­)
        examples = detail["examples"][:2]  # ìƒìœ„ 2ê°œë§Œ
        example_text = " ì˜ˆ: " + ", ".join(examples) if examples else ""

        return f"{desc}{example_text}"


    # 1. (AI) ëª…ë ¹ Type ì¶”ë¡ 
    def _classify_command_type(self, text: str):
        """ëª…ë ¹ íƒ€ì… ë¶„ë¥˜ (ìˆ˜ì •!)"""

        # 1. control (ì¥ë¹„ ì œì–´: ì¼œê¸°/ë„ê¸°/ì‘ë™)
        if any(kw in text for kw in ["ì¼œ", "êº¼", "ì‘ë™", "ì •ì§€", "on", "off", "start", "stop", "activate", "deactivate"]):
            return "control"

        # 2. broadcast (ë°©ì†¡ ë˜ëŠ” ì•Œë¦¼ ì†¡ì¶œ)
        if any(kw in text for kw in ["ë°©ì†¡", "ì•ˆë‚´", "ì†¡ì¶œ", "ì¶œë ¥", "ì¬ìƒ", "broadcast", "announce", "play"]):
            return "broadcast"

        # 3. log (ê¸°ë¡ ë˜ëŠ” ë¡œê·¸ ì¡°íšŒ)
        if any(kw in text for kw in ["ë¡œê·¸", "ê¸°ë¡", "ì´ë ¥", "history", "log"]):
            return "log"

        # 4. read (ê°’ ì¡°íšŒ / ì„¼ì„œ ë°ì´í„° ì½ê¸°)
        if any(kw in text for kw in ["ì½ì–´", "í™•ì¸", "ì¡°íšŒ", "ì¸¡ì •", "read", "measure", "get", "status"]):
            return "read"

        # 5. write (ì„¤ì • ë³€ê²½ / ë°ì´í„° ì“°ê¸°)
        if any(kw in text for kw in ["ì„¤ì •", "ë³€ê²½", "ì…ë ¥", "ì €ì¥", "ì“°ê¸°", "write", "set", "update"]):
            return "write"

        # ê¸°íƒ€: ë¶€ì •í™•í•œ ë°œìŒì€ AI ë¶„ë¥˜ê¸° ì‚¬ìš©
        z = self.classifier(
            text, candidate_labels=self.COMMAND_TYPES, multi_label=False
        )

        return z["labels"][0]


    # 2. (AI) ë¬´ì—‡ì„ ìˆ˜í–‰í• ì§€ ì¶”ë¡ 
    def _extract_what(self, text: str):
        """
        What ì¶”ì¶œ (NLI ëª¨ë¸ ì§ì ‘ ì‚¬ìš©)

        Args:
            text: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸

        Returns:
            str: ì¥ì¹˜ ì½”ë“œ
        """
        text_lower = text.lower()

        # 1ë‹¨ê³„: í‚¤ì›Œë“œ ì²´í¬
        for what_code, keywords in self.what_TYPES.items():
            if any(kw in text_lower for kw in keywords):
                log(f"  [í‚¤ì›Œë“œ ë§¤ì¹­] {what_code}")
                return what_code

        # 2ë‹¨ê³„: AI ë¶„ë¥˜ (ì§ì ‘ ì¶”ë¡ )
        log("  [AI ë¶„ë¥˜ ì‹œì‘]")

        # Tokenizerì™€ Model ì§ì ‘ ì‚¬ìš©
        tokenizer = self.classifier.tokenizer
        model = self.classifier.model

        scores = []

        for what_code in self.what_TYPES.keys():
            # Hypothesis ìƒì„±
            if what_code in self.HYP_DETAILED:
                hypothesis = self.HYP_DETAILED[what_code]["description"]
            else:
                hypothesis = f"{what_code} ì¥ì¹˜ë¥¼ ì œì–´í•˜ëŠ” ëª…ë ¹ì´ë‹¤."

            # Tokenization (premise, hypothesis ìŒ)
            inputs = tokenizer(
                text,  # Premise (ì…ë ¥ í…ìŠ¤íŠ¸)
                hypothesis,  # Hypothesis (ê°€ì„¤ ë¬¸ì¥)
                return_tensors="pt",  # PyTorch í…ì„œë¡œ ë°˜í™˜
                truncation=True,  # ê¸´ ë¬¸ì¥ ìë¥´ê¸°
                max_length=512  # ìµœëŒ€ ê¸¸ì´
            )

            # ëª¨ë¸ ì¶”ë¡ 
            with torch.no_grad():  # ê¸°ìš¸ê¸° ê³„ì‚° ì•ˆ í•¨ (ì†ë„ í–¥ìƒ)
                outputs = model(**inputs)
                logits = outputs.logits[0]  # [contradiction, neutral, entailment]

            # Entailment ì ìˆ˜ ì¶”ì¶œ (ë§ˆì§€ë§‰ ì¸ë±ìŠ¤)
            entailment_score = torch.softmax(logits, dim=0)[-1].item()

            scores.append((what_code, entailment_score))
            log(f"    {what_code}: {entailment_score:.4f}")

        # 3ë‹¨ê³„: ìµœê³  ì ìˆ˜ ì„ íƒ
        scores.sort(key=lambda x: x[1], reverse=True)
        best_label, best_score = scores[0]

        log(f"  [AI íŒì •] {best_label} (í™•ì‹ ë„: {best_score:.2%})")

        return best_label

    # def _extract_what(self, text: str):
    #     """What ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
    #     text_lower = text.lower()
    #
    #     # ëª…í™•í•˜ê²Œ í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš° ì¦‰ì‹œ return
    #     for what_code, keywords in self.what_TYPES.items():
    #         for keyword in keywords:
    #             if keyword in text_lower:
    #                 return what_code
    #
    #     # ìŒì„± ì¸ì‹ ë“± ëª…í™•í•˜ê²Œ ì…ë ¥ ë°›ì§€ ëª»í•œ ê²½ìš° NLU model ë™ì‘
    #     # í›„ë³´ ì¤‘ ì˜ë¯¸ì  ìœ ì‚¬ë„ì— ê°€ê¹Œìš´ ê°’ì„ ë°˜í™˜
    #
    #     log(f"[NLU-INPUT] {text}")
    #     log(f"[NLU-LABELS] {self.what_TYPES.keys()}")
    #     candidate_labels = list(self.what_TYPES.keys())  # ["DO", "DI", "ALERT", ...]
    #     log(f"[NLU-RAW] {candidate_labels}")
    #
    #     z = self.classifier(
    #         text,
    #         candidate_labels=candidate_labels,
    #         hypothesis_template=[],
    #         multi_label=True
    #     )
    #
    #     df = pd.DataFrame({
    #         'í›„ë³´': z['labels'],
    #         'ì •í™•ë„': z['scores']
    #     })
    #
    #     # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    #     df = df.sort_values('ì •í™•ë„', ascending=False).reset_index(drop=True)
    #     print(df)
    #
    #     return z["labels"][0]

    # 3. Target (write íƒ€ì…) ì¶”ë¡ 
    def _extract_value_for_write(self, text: str, numbers: list):
        """write ëª…ë ¹ìš© ê°’ ì¶”ì¶œ"""
        target_match = re.search(r'(\d+)\s*ë²ˆ', text)
        target = int(target_match.group(1)) if target_match else numbers[0]

        percent_match = re.search(r'(\d+(?:\.\d+)?)\s*%', text)
        if percent_match:
            value = float(percent_match.group(1)) / 100.0
            return target, value

        value_match = re.search(r'(?:ê°’|ì„¤ì •|ì„¸íŒ…).*?(\d+(?:\.\d+)?)', text)
        if value_match:
            value = float(value_match.group(1))
            if value > 1:
                value = value / 100.0
            return target, value

        return target, None

    # O1. ë‹¤ì¤‘ ëª…ë ¹ ì²˜ë¦¬
    def _split_commands(self, text: str):
        """ì—¬ëŸ¬ ëª…ë ¹ ë¶„ë¦¬"""
        parts = re.split(r'((?:ë„|ì¼œ|ì„¤ì •í•˜|í™œì„±í™”í•˜|ë¹„í™œì„±í™”í•˜|ì½)ê³ )', text)

        commands = []
        for i in range(0, len(parts) - 1, 2):
            connector = parts[i + 1]
            action_word = connector.replace("ê³ ", "")
            cmd_text = (parts[i].strip() + " " + action_word).strip()
            cmd_text = cmd_text.strip(',').strip()

            if cmd_text:
                commands.append(cmd_text)
                log(f"  [ë¶„ë¦¬] '{cmd_text}'")

        if len(parts) % 2 == 1:
            last_cmd = parts[-1].strip().strip(',').strip()
            if last_cmd:
                commands.append(last_cmd)
                log(f"  [ë¶„ë¦¬] '{last_cmd}'")

        return commands

    # 3. Target ì¶”ì¶œ
    def _extract_target(self, text: str):
        """ëŒ€ìƒ ì¶”ì¶œ"""
        numbers = [int(m) for m in re.findall(r'\d+', text)]

        if not numbers:
            if any(kw in text for kw in ["ëª¨ë‘", "ì „ì²´", "ë‹¤", "all"]):
                return {"type": "target", "values": list(range(1, 9))}
            return None

        if any(kw in text for kw in ["í¬íŠ¸", "target"]):
            target_type = "target"
        elif any(kw in text for kw in ["ì±„ë„", "channel", "ch"]):
            target_type = "channel"
        else:
            target_type = "target"

        range_patterns = [
            r'(\d+)\s*(?:ë²ˆ)?\s*(?:ì—ì„œ)\s*(\d+)\s*(?:ë²ˆ)?',
            r'(\d+)\s*(?:ë²ˆ)?\s*(?:ë¶€í„°)\s*(\d+)\s*(?:ë²ˆ)?(?:\s*ê¹Œì§€)?',
            r'(\d+)\s*[~\-]\s*(\d+)',
        ]

        for pattern in range_patterns:
            match = re.search(pattern, text)
            if match:
                start, end = int(match.group(1)), int(match.group(2))

                if start > end:
                    start, end = end, start

                range_nums = set(range(start, end + 1))

                if "ê·¸ë¦¬ê³ " in text or "í•˜ê³ " in text:
                    all_nums = range_nums.union(set(numbers))
                    values = sorted(list(all_nums))
                else:
                    values = list(range(start, end + 1))

                log(f"  [ë²”ìœ„ ì¸ì‹] {start}~{end} â†’ {values}")
                return {"type": target_type, "values": values}

        log(f"  [ê°œë³„ ì¸ì‹] {numbers}")
        return {"type": target_type, "values": numbers}

    # 4. Action ì¶”ì¶œ
    def _extract_action(self, text: str, cmd_type: str):
        """ë™ì‘ ì¶”ì¶œ"""
        if cmd_type == "control":
            if any(kw in text for kw in ["ì¼œ", "on", "start", "í™œì„±"]):
                return {"action": "on"}
            elif any(kw in text for kw in ["êº¼", "ë„", "off", "stop", "ë¹„í™œì„±"]):
                return {"action": "off"}

        elif cmd_type == "query":
            return {"action": "query"}

        elif cmd_type == "read":
            return {"action": "read"}

        elif cmd_type == "write":
            numbers = [int(m) for m in re.findall(r'\d+', text)]
            if numbers:
                target, value = self._extract_value_for_write(text, numbers)
                return {"action": "write", "target": target}
            return None

        elif cmd_type == "status":
            return {"action": "status"}

        elif cmd_type == "log":
            return {"action": "log"}

    def _parse_single_command_with_what(self, text: str, forced_what: str = None):
        """ë‹¨ì¼ ëª…ë ¹ ë¶„ì„"""
        cmd_type = self._classify_command_type(text)
        log(f"  íƒ€ì…: {cmd_type}")

        if forced_what:
            what = forced_what
        else:
            what = self._extract_what(text)
            log(f"  ì¥ì¹˜: {what}")

        if not what:
            return {"error": "ì¥ì¹˜ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

        action = self._extract_action(text, cmd_type)

        if cmd_type == "write" and action and "target" in action:
            command = {
                "type": cmd_type,
                "what": what,
                "target": action["target"],
                "action": action["action"],
            }
            log(f"  í¬íŠ¸: {action['target']}")
            log(f"  ê°’: {action['value']}")
            return command


        target = self._extract_target(text)

        if not target:
            print("íƒ€ì¼“ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆ ëœë‹ˆë‹¤.")
            # return {"error": "ëŒ€ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        else:
            log(f"  {target['type']}: {target['values']}")

        if not action:
            print("ë™ì‘ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆ ëœë‹ˆë‹¤.")
            # return {"error": "ë™ì‘ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

        command = {"type": cmd_type, "what": what}

        if target and len(target['values']) == 1:
            command[target['type']] = target['values'][0]
            command.update(action)

        return command

    def _parse_single_command(self, text: str):
        """ë‹¨ì¼ ëª…ë ¹ ë¶„ì„"""

        keywords = self._extract_keywords(text, 5)
        log(f"  [í‚¤ì›Œë“œ] : {keywords}")

        return self._parse_single_command_with_what(keywords, forced_what=None)


    def parse_text(self, text: str):
        """í…ìŠ¤íŠ¸ ë¶„ì„ (ë‹¤ì¤‘ ëª…ë ¹ ì§€ì›)"""
        if not text or not text.strip():
            return {"error": "ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."}

        log(f"[ê°ì§€í•œ í…ìŠ¤íŠ¸] {text}")
        log("=" * 60)

        # if any(kw in text for kw in ["ë„ê³ ", "ì¼œê³ ", "í•˜ê³ ", "ë‹¤ìŒì—"]):
        #     log("[ë‹¤ì¤‘ ëª…ë ¹ ê°ì§€]")
        #
        #     common_what = self._extract_what(text)
        #     log(f"  ê³µí†µ ì¥ì¹˜: {common_what}")
        #
        #     commands_text = self._split_commands(text)
        #     log(f"  ë¶„ë¦¬ëœ ëª…ë ¹: {len(commands_text)}ê°œ")
        #
        #     results = []
        #     last_what = common_what

            # log("=" * 60)
            #
            # if len(results) == 0:
            #     return {"error": "ìœ íš¨í•œ ëª…ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            # elif len(results) == 1:
            #     return results[0]
            # else:
            #     return {"ëª…ë ¹ì–´": results, "ëª…ë ¹ ê°œìˆ˜": len(results)}
            #
            # for i, cmd_text in enumerate(commands_text, 1):
            #     log(f"[ëª…ë ¹ {i}] {cmd_text}")
            #
            #     what = self._extract_what(cmd_text)
            #
            #     if not what:
            #         what = last_what
            #         log(f"  ì¥ì¹˜: {what} (ìƒì†ë¨)")
            #     else:
            #         last_what = what
            #         log(f"  ì¥ì¹˜: {what}")
            #
            #     if not what:
            #         log(f"  âš ï¸ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            #         continue
            #
            #     result = self._parse_single_command_with_what(cmd_text, what)
            #
            #     if "error" not in result:
            #         results.append(result)

        what = self._extract_what(text)
        log(f"  ì¥ì¹˜: {what}")

        if not what:
            log(f"  âš ï¸ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ìŠ¤í‚µí•©ë‹ˆë‹¤.")

        result = self._parse_single_command(text)

        log("=" * 60)
        return result